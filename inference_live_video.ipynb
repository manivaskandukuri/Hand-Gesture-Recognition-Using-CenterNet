{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1649099638515,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "gFU4RZ9DHkiQ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import os.path as osp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manivas\\Downloads\\CenterNet\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1649099638519,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "vnxh_hzRGjVg"
   },
   "outputs": [],
   "source": [
    "from generators.pascal import PascalVocGenerator\n",
    "from generators.csv_ import CSVGenerator\n",
    "from models.resnet import centernet\n",
    "from generators.utils import affine_transform, get_affine_transform\n",
    "from eval.common import _get_detections, _get_annotations, evaluate, _compute_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1649099638520,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "trrw1Jp0lL-N"
   },
   "outputs": [],
   "source": [
    "args_test_annotations_path = 'Ouhands_bounding/test_colour/test_annot.csv'\n",
    "args_classes_path = 'Ouhands_bounding/classes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1649099639198,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "EjZR6FzNkrKn"
   },
   "outputs": [],
   "source": [
    "generator = CSVGenerator(\n",
    "    args_test_annotations_path,\n",
    "    args_classes_path,\n",
    "    shuffle_groups=True,\n",
    ")\n",
    "\n",
    "generator_input_size = 512\n",
    "generator_num_classes = 10\n",
    "generator_classes = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'H': 6,\n",
    "    'I': 7,\n",
    "    'J': 8,\n",
    "    'K': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649099639200,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "iQ1giQduGkKI",
    "outputId": "8f0f4afe-051a-4fe2-8366-8bbe14aac376"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"generator = PascalVocGenerator(\\n    'pascal_datasets/test/VOC2007',\\n    'test',\\n    shuffle_groups=False,\\n    skip_truncated=False,\\n    skip_difficult=True,\\n)\\n\\ngenerator_input_size = 512\\ngenerator_num_classes = 20\\ngenerator_classes = {\\n    'aeroplane': 0,\\n    'bicycle': 1,\\n    'bird': 2,\\n    'boat': 3,\\n    'bottle': 4,\\n    'bus': 5,\\n    'car': 6,\\n    'cat': 7,\\n    'chair': 8,\\n    'cow': 9,\\n    'diningtable': 10,\\n    'dog': 11,\\n    'horse': 12,\\n    'motorbike': 13,\\n    'person': 14,\\n    'pottedplant': 15,\\n    'sheep': 16,\\n    'sofa': 17,\\n    'train': 18,\\n    'tvmonitor': 19\\n}\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "'''generator = PascalVocGenerator(\n",
    "    'pascal_datasets/test/VOC2007',\n",
    "    'test',\n",
    "    shuffle_groups=False,\n",
    "    skip_truncated=False,\n",
    "    skip_difficult=True,\n",
    ")\n",
    "\n",
    "generator_input_size = 512\n",
    "generator_num_classes = 20\n",
    "generator_classes = {\n",
    "    'aeroplane': 0,\n",
    "    'bicycle': 1,\n",
    "    'bird': 2,\n",
    "    'boat': 3,\n",
    "    'bottle': 4,\n",
    "    'bus': 5,\n",
    "    'car': 6,\n",
    "    'cat': 7,\n",
    "    'chair': 8,\n",
    "    'cow': 9,\n",
    "    'diningtable': 10,\n",
    "    'dog': 11,\n",
    "    'horse': 12,\n",
    "    'motorbike': 13,\n",
    "    'person': 14,\n",
    "    'pottedplant': 15,\n",
    "    'sheep': 16,\n",
    "    'sofa': 17,\n",
    "    'train': 18,\n",
    "    'tvmonitor': 19\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649099639201,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "AtrDOh_iZWZZ",
    "outputId": "dd63d48d-fc6c-492f-ec2f-20d6f8c8eb8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def preprocess_image(image, c, s, tgt_w, tgt_h):\\n  trans_input = get_affine_transform(c, s, (tgt_w, tgt_h))\\n  image = cv2.warpAffine(image, trans_input, (tgt_w, tgt_h), flags=cv2.INTER_LINEAR)\\n  image = image.astype(np.float32)\\n\\n  image[..., 0] -= 103.939\\n  image[..., 1] -= 116.779\\n  image[..., 2] -= 123.68\\n\\n  image[..., 0] /= 255.0\\n  image[..., 1] /= 255.0\\n  image[..., 2] /= 255.0\\n\\n  return image'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def preprocess_image(image, c, s, tgt_w, tgt_h):\n",
    "  trans_input = get_affine_transform(c, s, (tgt_w, tgt_h))\n",
    "  image = cv2.warpAffine(image, trans_input, (tgt_w, tgt_h), flags=cv2.INTER_LINEAR)\n",
    "  image = image.astype(np.float32)\n",
    "\n",
    "  image[..., 0] -= 103.939\n",
    "  image[..., 1] -= 116.779\n",
    "  image[..., 2] -= 123.68\n",
    "\n",
    "  image[..., 0] /= 255.0\n",
    "  image[..., 1] /= 255.0\n",
    "  image[..., 2] /= 255.0\n",
    "\n",
    "  return image'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3168,
     "status": "ok",
     "timestamp": 1649099642359,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "HPpeZ5KZGrVg"
   },
   "outputs": [],
   "source": [
    "model_path = 'checkpoints/End2End_Resnet50_danet_1_normalization_2_2000/csv_57_0.8407_1.1972_2.2595.h5'\n",
    "num_classes = generator_num_classes\n",
    "classes = list(generator_classes.keys())\n",
    "flip_test = False\n",
    "nms = True\n",
    "keep_resolution = False\n",
    "score_threshold = 0.2\n",
    "iou_threshold = 0.5\n",
    "max_detections = 100\n",
    "colors = [np.random.randint(0, 256, 3).tolist() for i in range(num_classes)]\n",
    "model, prediction_model, debug_model = centernet(num_classes=num_classes,\n",
    "                                                 backbone='resnet50',\n",
    "                                                 score_threshold=score_threshold,\n",
    "                                                 nms=nms,\n",
    "                                                 flip_test=flip_test\n",
    "                                                 )\n",
    "prediction_model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31465,
     "status": "ok",
     "timestamp": 1649099673811,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "UBcskuVt8aNr",
    "outputId": "9e2b4cc6-040f-4f0d-a8e6-15b3e82f1b17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# run evaluation\\naverage_precisions, f1_scores = evaluate(\\n            generator,\\n            prediction_model,\\n            iou_threshold=iou_threshold,\\n            score_threshold=score_threshold,\\n            max_detections=max_detections,\\n            visualize=False\\n        )\\n\\n\\n# compute per class average precision\\ntotal_instances = []\\nprecisions = []\\nfor label, (average_precision, num_annotations) in average_precisions.items():\\n    print('{:.0f} instances of class'.format(num_annotations),\\n          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\\n    total_instances.append(num_annotations)\\n    precisions.append(average_precision)\\n\\nmean_ap = sum(precisions) / sum(x > 0 for x in total_instances)\\nprint('mAP: {:.4f}'.format(mean_ap))\\n\\n\\n# compute per class F1-score\\ntotal_instances = []\\nscores = []\\nfor label, f1_score in f1_scores.items():\\n    print('{:.0f} instances of class'.format(num_annotations),\\n              generator.label_to_name(label), 'with F1-score: {:.4f}'.format(f1_score))\\n    total_instances.append(num_annotations)\\n    scores.append(f1_score)\\n\\nmean_f1_score = sum(scores) / sum(x > 0 for x in total_instances)\\nprint('Mean F1-score: {:.4f}'.format(mean_f1_score))\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# run evaluation\n",
    "average_precisions, f1_scores = evaluate(\n",
    "            generator,\n",
    "            prediction_model,\n",
    "            iou_threshold=iou_threshold,\n",
    "            score_threshold=score_threshold,\n",
    "            max_detections=max_detections,\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "\n",
    "# compute per class average precision\n",
    "total_instances = []\n",
    "precisions = []\n",
    "for label, (average_precision, num_annotations) in average_precisions.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "          generator.label_to_name(label), 'with average precision: {:.4f}'.format(average_precision))\n",
    "    total_instances.append(num_annotations)\n",
    "    precisions.append(average_precision)\n",
    "\n",
    "mean_ap = sum(precisions) / sum(x > 0 for x in total_instances)\n",
    "print('mAP: {:.4f}'.format(mean_ap))\n",
    "\n",
    "\n",
    "# compute per class F1-score\n",
    "total_instances = []\n",
    "scores = []\n",
    "for label, f1_score in f1_scores.items():\n",
    "    print('{:.0f} instances of class'.format(num_annotations),\n",
    "              generator.label_to_name(label), 'with F1-score: {:.4f}'.format(f1_score))\n",
    "    total_instances.append(num_annotations)\n",
    "    scores.append(f1_score)\n",
    "\n",
    "mean_f1_score = sum(scores) / sum(x > 0 for x in total_instances)\n",
    "print('Mean F1-score: {:.4f}'.format(mean_f1_score))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  2.8663246631622314\n",
      "Elapsed time:  0.44492077827453613\n",
      "Elapsed time:  0.4837040901184082\n",
      "Elapsed time:  0.4653587341308594\n",
      "Elapsed time:  0.4469616413116455\n",
      "Elapsed time:  0.434661865234375\n",
      "Elapsed time:  0.4513859748840332\n",
      "Elapsed time:  0.44323158264160156\n",
      "Elapsed time:  0.4564692974090576\n",
      "Elapsed time:  0.4426560401916504\n",
      "Elapsed time:  0.42006897926330566\n",
      "Elapsed time:  0.4316840171813965\n",
      "Elapsed time:  0.42943358421325684\n",
      "Elapsed time:  0.44704627990722656\n",
      "Elapsed time:  0.42949342727661133\n",
      "Elapsed time:  0.44109296798706055\n",
      "Elapsed time:  0.46184539794921875\n",
      "Elapsed time:  0.45400404930114746\n",
      "Elapsed time:  0.46065306663513184\n",
      "Elapsed time:  0.4780080318450928\n",
      "Elapsed time:  0.45837926864624023\n",
      "Elapsed time:  0.44489169120788574\n",
      "Elapsed time:  0.43922972679138184\n",
      "Elapsed time:  0.45816802978515625\n",
      "Elapsed time:  0.4402801990509033\n"
     ]
    }
   ],
   "source": [
    "for i in range(300,325):\n",
    "    image = generator.load_image(i)\n",
    "    #path = 'pascal_datasets/test/VOC2007/JPEGImages/009915.jpg'\n",
    "    #image = cv2.imread(path)\n",
    "    src_image = image.copy()\n",
    "\n",
    "    c = np.array([image.shape[1] / 2., image.shape[0] / 2.], dtype=np.float32)\n",
    "    s = max(image.shape[0], image.shape[1]) * 1.0\n",
    "\n",
    "    tgt_w = generator.input_size\n",
    "    tgt_h = generator.input_size\n",
    "    image = generator.preprocess_image(image, c, s, tgt_w=tgt_w, tgt_h=tgt_h)\n",
    "    if flip_test:\n",
    "        flipped_image = image[:, ::-1]\n",
    "        inputs = np.stack([image, flipped_image], axis=0)\n",
    "    else:\n",
    "        inputs = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # run network\n",
    "    start = time.time()\n",
    "    detections = prediction_model.predict_on_batch(inputs)[0]\n",
    "    print(\"Elapsed time: \", time.time() - start)\n",
    "    scores = detections[:, 4]\n",
    "\n",
    "    # sort by score\n",
    "    indices = np.argsort(-scores)[0]\n",
    "\n",
    "    if (scores[indices]>=score_threshold):\n",
    "        # select those detections\n",
    "        detections = np.expand_dims(detections[indices], axis=0)\n",
    "\n",
    "        detections_copy = detections.copy()\n",
    "        detections = detections.astype(np.float64)\n",
    "        trans = get_affine_transform(c, s, (tgt_w // 4, tgt_h // 4), inv=1)\n",
    "\n",
    "        for j in range(detections.shape[0]):\n",
    "            detections[j, 0:2] = affine_transform(detections[j, 0:2], trans)\n",
    "            detections[j, 2:4] = affine_transform(detections[j, 2:4], trans)\n",
    "\n",
    "            detections[:, [0, 2]] = np.clip(detections[:, [0, 2]], 0, src_image.shape[1])\n",
    "            detections[:, [1, 3]] = np.clip(detections[:, [1, 3]], 0, src_image.shape[0])\n",
    "\n",
    "        '''all_detections = []\n",
    "        for class_id in range(generator.num_classes()):\n",
    "        class_detections = tf.boolean_mask(detections, tf.equal(detections[:, 5], class_id))\n",
    "        #print(\"For class-{} Class detections shape before:\".format(class_id), class_detections.shape)\n",
    "        nms_keep_indices = tf.image.non_max_suppression(tf.cast(class_detections[:, :4],tf.float32),\n",
    "                                                        tf.cast(class_detections[:, 4],tf.float32),\n",
    "                                                        5,\n",
    "                                                        iou_threshold=iou_threshold,\n",
    "                                                        score_threshold=score_threshold)\n",
    "        class_detections = tf.gather(class_detections, nms_keep_indices)\n",
    "\n",
    "        if (class_detections.shape[0]>0):\n",
    "          all_detections.append(class_detections)\n",
    "\n",
    "        if (all_detections!=[]):  \n",
    "        all_detections = tf.concat(all_detections, axis=0)'''\n",
    "\n",
    "        for detection in detections:\n",
    "            #detection = detections.numpy()\n",
    "            xmin = int(round(detection[0]))\n",
    "            ymin = int(round(detection[1]))\n",
    "            xmax = int(round(detection[2]))\n",
    "            ymax = int(round(detection[3]))\n",
    "            score = '{:.4f}'.format(detection[4])\n",
    "            class_id = int(detection[5])\n",
    "            color = colors[class_id]\n",
    "            class_name = classes[class_id]\n",
    "            label = '-'.join([class_name, score])\n",
    "            ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1, 3)\n",
    "            cv2.rectangle(src_image, (xmin, ymin), (xmax, ymax), color, 3)\n",
    "            cv2.rectangle(src_image, (xmin, ymax - ret[1] - baseline), (xmin + ret[0], ymax), color, -1)\n",
    "            cv2.putText(src_image, label, (xmin, ymax - baseline), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 3)\n",
    "\n",
    "    #image_fname = 'test_{}'.format(i)\n",
    "    #cv2.imwrite('test/{}.jpg'.format(image_fname), src_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1649099674486,
     "user": {
      "displayName": "Manivas Kandukuri",
      "userId": "11028743084028902847"
     },
     "user_tz": -330
    },
    "id": "BgBHULVu-vFS",
    "outputId": "efa22742-866f-4496-dbb7-063ae698f611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.4792916774749756\n",
      "Elapsed time:  0.41965770721435547\n",
      "Elapsed time:  0.4160313606262207\n",
      "Elapsed time:  0.39447546005249023\n",
      "Elapsed time:  0.5317249298095703\n",
      "Elapsed time:  0.4207019805908203\n",
      "Elapsed time:  0.38851118087768555\n",
      "Elapsed time:  0.39091014862060547\n",
      "Elapsed time:  0.3981137275695801\n",
      "Elapsed time:  0.3961944580078125\n",
      "Elapsed time:  0.3963735103607178\n",
      "Elapsed time:  0.39096879959106445\n",
      "Elapsed time:  0.3924553394317627\n",
      "Elapsed time:  0.39340901374816895\n",
      "Elapsed time:  0.3876042366027832\n",
      "Elapsed time:  0.39246702194213867\n",
      "Elapsed time:  0.3862922191619873\n",
      "Elapsed time:  0.3928217887878418\n",
      "Elapsed time:  0.40975046157836914\n",
      "Elapsed time:  0.3905797004699707\n",
      "Elapsed time:  0.39238953590393066\n",
      "Elapsed time:  0.3893280029296875\n",
      "Elapsed time:  0.4047279357910156\n",
      "Elapsed time:  0.3883330821990967\n",
      "Elapsed time:  0.40960693359375\n",
      "Elapsed time:  0.4321587085723877\n",
      "Elapsed time:  0.4664921760559082\n",
      "Elapsed time:  0.4569876194000244\n",
      "Elapsed time:  0.47500038146972656\n",
      "Elapsed time:  0.44364237785339355\n",
      "Elapsed time:  0.4502899646759033\n",
      "Elapsed time:  0.44279026985168457\n",
      "Elapsed time:  0.4389503002166748\n",
      "Elapsed time:  0.4527626037597656\n",
      "Elapsed time:  0.442716121673584\n",
      "Elapsed time:  0.4649848937988281\n",
      "Elapsed time:  0.4415302276611328\n",
      "Elapsed time:  0.4670567512512207\n",
      "Elapsed time:  0.44209790229797363\n",
      "Elapsed time:  0.45865774154663086\n",
      "Elapsed time:  0.47387242317199707\n",
      "Elapsed time:  0.45811891555786133\n",
      "Elapsed time:  0.47771215438842773\n",
      "Elapsed time:  0.4875454902648926\n",
      "Elapsed time:  0.5299341678619385\n",
      "Elapsed time:  0.5011270046234131\n",
      "Elapsed time:  0.5192444324493408\n",
      "Elapsed time:  0.5663020610809326\n",
      "Elapsed time:  0.553612232208252\n",
      "Elapsed time:  0.5575511455535889\n",
      "Elapsed time:  0.586113691329956\n",
      "Elapsed time:  0.5124659538269043\n",
      "Elapsed time:  0.4798879623413086\n",
      "Elapsed time:  0.6276659965515137\n",
      "Elapsed time:  0.5812640190124512\n"
     ]
    }
   ],
   "source": [
    "# Object to capture the live video using the default camera of PC\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# Reading each frame of the live video and making detections on the video frames\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Reading the frame of captured vide\n",
    "    _,image = cap.read()\n",
    "\n",
    "\n",
    "    src_image = image.copy()\n",
    "\n",
    "    c = np.array([image.shape[1] / 2., image.shape[0] / 2.], dtype=np.float32)\n",
    "    s = max(image.shape[0], image.shape[1]) * 1.0\n",
    "\n",
    "    tgt_w = generator.input_size\n",
    "    tgt_h = generator.input_size\n",
    "    image = generator.preprocess_image(image, c, s, tgt_w=tgt_w, tgt_h=tgt_h)\n",
    "    if flip_test:\n",
    "        flipped_image = image[:, ::-1]\n",
    "        inputs = np.stack([image, flipped_image], axis=0)\n",
    "    else:\n",
    "        inputs = np.expand_dims(image, axis=0)\n",
    "\n",
    "        \n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # run network\n",
    "    detections = prediction_model.predict_on_batch(inputs)[0]\n",
    "    \n",
    "    scores = detections[:, 4]\n",
    "\n",
    "    # sort by score\n",
    "    indices = np.argsort(-scores)[0]\n",
    "    \n",
    "    # End time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    print(\"Elapsed time: \", elapsed_time)\n",
    "\n",
    "    if (scores[indices]>=score_threshold):\n",
    "        # select those detections\n",
    "        detections = np.expand_dims(detections[indices], axis=0)\n",
    "\n",
    "        detections_copy = detections.copy()\n",
    "        detections = detections.astype(np.float64)\n",
    "        trans = get_affine_transform(c, s, (tgt_w // 4, tgt_h // 4), inv=1)\n",
    "\n",
    "        for j in range(detections.shape[0]):\n",
    "            detections[j, 0:2] = affine_transform(detections[j, 0:2], trans)\n",
    "            detections[j, 2:4] = affine_transform(detections[j, 2:4], trans)\n",
    "\n",
    "            detections[:, [0, 2]] = np.clip(detections[:, [0, 2]], 0, src_image.shape[1])\n",
    "            detections[:, [1, 3]] = np.clip(detections[:, [1, 3]], 0, src_image.shape[0])\n",
    "\n",
    "        '''all_detections = []\n",
    "        for class_id in range(generator.num_classes()):\n",
    "        class_detections = tf.boolean_mask(detections, tf.equal(detections[:, 5], class_id))\n",
    "        #print(\"For class-{} Class detections shape before:\".format(class_id), class_detections.shape)\n",
    "        nms_keep_indices = tf.image.non_max_suppression(tf.cast(class_detections[:, :4],tf.float32),\n",
    "                                                        tf.cast(class_detections[:, 4],tf.float32),\n",
    "                                                        5,\n",
    "                                                        iou_threshold=iou_threshold,\n",
    "                                                        score_threshold=score_threshold)\n",
    "        class_detections = tf.gather(class_detections, nms_keep_indices)\n",
    "\n",
    "        if (class_detections.shape[0]>0):\n",
    "          all_detections.append(class_detections)\n",
    "\n",
    "        if (all_detections!=[]):  \n",
    "        all_detections = tf.concat(all_detections, axis=0)'''\n",
    "\n",
    "        for detection in detections:\n",
    "            #detection = detections.numpy()\n",
    "            xmin = int(round(detection[0]))\n",
    "            ymin = int(round(detection[1]))\n",
    "            xmax = int(round(detection[2]))\n",
    "            ymax = int(round(detection[3]))\n",
    "            score = '{:.4f}'.format(detection[4])\n",
    "            class_id = int(detection[5])\n",
    "            color = colors[class_id]\n",
    "            class_name = classes[class_id]\n",
    "            label = '-'.join([class_name, score])\n",
    "            ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1, 3)\n",
    "            cv2.rectangle(src_image, (xmin, ymin), (xmax, ymax), color, 3)\n",
    "            cv2.rectangle(src_image, (xmin, ymax - ret[1] - baseline), (xmin + ret[0], ymax), color, -1)\n",
    "            cv2.putText(src_image, label, (xmin, ymax - baseline), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 3)\n",
    "\n",
    "    \n",
    "    fps = 1/elapsed_time\n",
    "    \n",
    "    #cv2.putText(src_image, \"FPS: \" + str(round(elapsed_time, 4)), (300, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3)\n",
    "    \n",
    "    # Display the marked images with a duration of 1 ms \n",
    "    # Click on the camera window created by cv2\n",
    "    cv2.imshow(\"Objects detection on live video\", src_image)\n",
    "        \n",
    "    # Press key q to stop the live detection and turn off the camera\n",
    "    if ord(\"q\") == cv2.waitKey(1):\n",
    "        break\n",
    "\n",
    "# Releases the I/O device (i.e.,camera) by opencv            \n",
    "cap.release()\n",
    "\n",
    "# Close all the opened windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeqJ6bGKEPbL"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOItbFEQLMj3QTzhkFKuj3x",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1nBy-fMGP300Zw3ko8LTxyBLvzXqWpaUs",
   "name": "inference.ipynb",
   "provenance": [
    {
     "file_id": "1tNT1kWsLzG9Zd8EqoLU_tXEwaAOuxIB5",
     "timestamp": 1634674213348
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
